<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Video-GPT via Next Clip Diffusion">
  <meta name="keywords" content="Title">
<!--  <meta name="viewport" content="width=device-width, initial-scale=2">-->
  <meta name="viewport" content="width=device-width">
  <title>Video-GPT via Next Clip Diffusion</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-9VZKE74FPW"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<style>
  body {
    max-width: 2400px;
    margin: 0 auto;
  }
</style>

<body>


<section class="hero" style="margin-bottom: 10px;">
  <div class="hero-body">
<!--    <div class="container is-max-desktop">-->
      <div class="container is-fullhd">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Video-GPT via Next Clip Diffusion</h1>
          <div class="is-size-5 publication-authors">

              <span class="author-block">
                <a href="https://scholar.google.com.hk/citations?user=PGaDirMAAAAJ&hl=zh-CN&oi=ao">Shaobin Zhuang</a><sup>1&dagger;</sup>,</span>
              <span class="author-block">
                <a>Zhipeng Huang</a><sup>5&dagger;</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=R_psgxkAAAAJ&view_op=list_works">Ying Zhang</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://github.com/zituitui">Fangyikang Wang</a><sup>6&dagger;</sup>,</span>
              <span class="author-block">
                <a>Canmiao Fu</a><sup>2</sup>,</span>
              <span class="author-block">
                <a>Binxin Yang</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=-GLJ0D4AAAAJ&view_op=list_works&sortby=pubdate">Chong Sun</a><sup>2</sup></span>
              <span class="author-block">
                <a>Chen Li</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=hD948dkAAAAJ&hl=zh-CN">Yali Wang</a><sup>3,4&Dagger;</sup></span>
            </div>
  
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Shanghai Jiao Tong University&nbsp</span>
              <span class="author-block"><sup>2</sup>WeChat Vision, Tencent Inc.&nbsp</span>
              <span class="author-block"><sup>3</sup>Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences&nbsp</span><br />
              <span class="author-block"><sup>4</sup>Shanghai AI Laboratory&nbsp</span>
              <span class="author-block"><sup>5</sup>University of Science and Technology of China</span>
              <span class="author-block"><sup>5</sup>Zhejiang University</span>
            </div>
          
          <div class="is-size-6 publication-authors">
              <span class="author-block"><sup>&dagger;</sup>Work done as interns at WeChat Vision, Tencent Inc.</span> 
              <span class="author-block"><sup>&Dagger;</sup>Corresponding authors.</span>
            </div>

          <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2401.09414"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="ai ai-arxiv"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/GrayShine/Video-GPT"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fa-brands fa-hugging-face"></i>
                    </span>
                    <span>Model (Coming Soon)</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/zhuangshaobin/Video-GPT"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Coming Soon)</span>
                    </a>
                </span>
  
              </div>
  
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" style="padding-top: 0;">
  <div class="container is-fullhd">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- <h2 class="title is-3">Abstract</h2> -->
        <div class="content has-text-justified" style="font-size: 20.171px;">
          <p>
            <strong>Abstract:</strong> GPT has shown its remarkable success in natural language processing. However, the language sequence is not sufficient to describe spatial-temporal details in the visual world. Alternatively, the video sequence is good at capturing such details. Motivated by this fact, we propose a concise Video-GPT in this paper by treating video as new language for visual world modeling. By analogy to next token prediction in GPT, we introduce a novel next clip diffusion paradigm for pretraining Video-GPT. Different from the previous works, this distinct paradigm allows Video-GPT to tackle both short-term generation and long-term prediction, by autoregressively denoising the noisy clip according to the clean clips in the history. Extensive experiments show our Video-GPT achieves the state-of-the-art performance on video prediction, which is the key factor towards world modeling (Physics-IQ Benchmark: Video-GPT 34.97 vs. Kling 23.64 vs. Wan 20.89). Moreover, it can be well adapted on 6 mainstream video tasks in both video generation and understanding, showing its great generalization capacity in downstream.
          </p>
        </div>
      </div>
    </div>

</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="container is-max-maxwidth">

        <h2 class="title is-3">Overview</h2>
        <p style="text-align: justify;">
          Video-GPT is a video self-supervised generative pre-trained model 
          which treats video as new language for visual world modeling by 
          next clip diffusion. It is designed to be simple, flexible, and easy to follow. 
          Previous works on visual generation relies heavily on supervisory signals 
          from textual modalities (such as Sora, WanX, HunyuanVideo, MovieGen). 
          However, vision, as a natural ability of human beings, was formed even earlier than 
          language. Therefore, we believe that the information of the visual modality itself 
          is sufficient to support the model to model the world. 
        </p>
        <!-- <p>
          (Story from <span style="color:rgb(147, 147, 229);"><a href="https://phenaki.github.io/">Phenaki.github.io</a></span>)
        </p> -->
        <!-- <h2 class="title is-5">(Story from <span style="color:rgb(147, 147, 229);"><a href="https://phenaki.github.io/">Phenaki.github.io</a></span>) -->
        </h2>
        <img src="static/paper_img/teaser.png" alt="teaser.png" />
    </div>
  </div>
</section>




<!-- --------------  Physical World Modeling -------------- -->
<section class="section">
  <h2 class="title has-text-centered">Powerful Zero-Shot Video Prediction Capabilities</h2>
  <p class="subtitle is-6 has-text-centered">
    The model makes future predictions based on a given conditional video, thereby examining the model's ability to model the physical world.
  </p>
  <div class="columns is-centered has-text-centered">
    <img width="800" height="600" src="static/paper_img/phys_bench.png" alt="phys_bench.png" />
  </div>
  <div class="columns is-centered has-text-centered">
    <img width="860" height="300" src="static/paper_img/k600.png" alt="k600.png" />
  </div>
  <h3 class="title has-text-centered">Physical World Modeling Visualization</h3>
  <!-- ☆☆☆ 关键：三列一行，满 12 分自动换行 ☆☆☆ -->
  <!-- 新增 phys-shift 用来做定向位移 -->
  <div class="columns is-multiline is-centered is-variable is-1 phys-shift">

    <!-- item 1 -->
    <div class="column is-4 has-text-centered">
      <video width="176" height="176" class="demo-video clickplay" controls>
        <source src="static/phys_bench/LVM/video1.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">LVM</p>
    </div>

    <!-- item 2 -->
    <div class="column is-4 has-text-centered">
      <video width="281.6" height="176" class="demo-video clickplay" controls>
        <source src="static/phys_bench/Seine/video1.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">Seine</p>
    </div>

    <!-- item 3 -->
    <div class="column is-4 has-text-centered">
      <video width="320" height="176" class="demo-video clickplay" controls>
        <source src="static/phys_bench/Video-GPT/video1.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">Video-GPT</p>
    </div>

    <!-- item 4 -->
    <div class="column is-4 has-text-centered">
      <video width="176" height="176" class="demo-video clickplay" controls>
        <source src="static/phys_bench/LVM/video2.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">LVM</p>
    </div>

    <!-- item 5 -->
    <div class="column is-4 has-text-centered">
      <video width="281.6" height="176" class="demo-video clickplay" controls>
        <source src="static/phys_bench/Seine/video2.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">Seine</p>
    </div>

    <!-- item 6 -->
    <div class="column is-4 has-text-centered">
      <video width="320" height="176" class="demo-video clickplay" controls>
        <source src="static/phys_bench/Video-GPT/video2.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">Video-GPT</p>
    </div>

  </div>
  <p class="subtitle is-6 has-text-centered">
    It is clear that our Video-GPT can predict the future of the video more accurately and is less likely to crash, 
    while other methods not only find it difficult to simulate the laws of physics, 
    but also often crash the video content.
  </p>





  <h3 class="title has-text-centered">Long Video Prediction Visualization</h3>
  <!-- ☆☆☆ 关键：三列一行，满 12 分自动换行 ☆☆☆ -->
  <!-- 新增 phys-shift 用来做定向位移 -->
  <div class="columns is-multiline is-centered is-variable is-1 phys-shift_">

    <!-- item 1 -->
    <div class="column is-3 has-text-centered">
      <video width="176" height="320" class="demo-video clickplay" controls>
        <source src="static/LVM_long_video_prediction_condition/video4.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">Condition</p>
    </div>

    <!-- item 2 -->
    <div class="column is-3 has-text-centered">
      <video width="176" height="320" class="demo-video clickplay" controls>
        <source src="static/LVM_long_video_prediction/video4.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">Predicted by Video-GPT</p>
    </div>

    <!-- item 3 -->
    <div class="column is-3 has-text-centered">
      <video width="176" height="320" class="demo-video clickplay" controls>
        <source src="static/LVM_long_video_prediction_condition/video5.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">Condition</p>
    </div>

    <!-- item 4 -->
    <div class="column is-3 has-text-centered">
      <video width="176" height="320" class="demo-video clickplay" controls>
        <source src="static/LVM_long_video_prediction/video5.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">Predicted by Video-GPT</p>
    </div>


  </div>
  <div class="columns is-multiline is-centered is-variable is-1 phys-shift__">

    <!-- item 1 -->
    <div class="column is-3 has-text-centered">
      <video width="320" height="176" class="demo-video clickplay" controls>
        <source src="static/LVM_long_video_prediction_condition/video1.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">Condition</p>
    </div>

    <!-- item 2 -->
    <div class="column is-3 has-text-centered">
      <video width="320" height="176" class="demo-video clickplay" controls>
        <source src="static/LVM_long_video_prediction/video1.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">Predicted by Video-GPT</p>
    </div>

    <!-- item 3 -->
    <div class="column is-3 has-text-centered">
      <video width="320" height="176" class="demo-video clickplay" controls>
        <source src="static/LVM_long_video_prediction_condition/video2.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">Condition</p>
    </div>

    <!-- item 4 -->
    <div class="column is-3 has-text-centered">
      <video width="320" height="176" class="demo-video clickplay" controls>
        <source src="static/LVM_long_video_prediction/video2.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">Predicted by Video-GPT</p>
    </div>

    <!-- item 5 -->
    <div class="column is-3 has-text-centered">
      <video width="320" height="176" class="demo-video clickplay" controls>
        <source src="static/LVM_long_video_prediction_condition/video3.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">Condition</p>
    </div>

    <!-- item 6 -->
    <div class="column is-3 has-text-centered">
      <video width="320" height="176" class="demo-video clickplay" controls>
        <source src="static/LVM_long_video_prediction/video3.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">Predicted by Video-GPT</p>
    </div>

    <!-- item 7 -->
    <div class="column is-3 has-text-centered">
      <video width="320" height="176" class="demo-video clickplay" controls>
        <source src="static/LVM_long_video_prediction_condition/video6.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">Condition</p>
    </div>

    <!-- item 8 -->
    <div class="column is-3 has-text-centered">
      <video width="320" height="176" class="demo-video clickplay" controls>
        <source src="static/LVM_long_video_prediction/video6.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">Predicted by Video-GPT</p>
    </div>


  </div>





</section>

<!-- ---------- 仅负责“错位”位移的样式 ---------- -->
<!-- <style>
/* 基础位移：第 1、4 个向右；第 3、6 个向左 */
.phys-shift .column:nth-of-type(1),
.phys-shift .column:nth-of-type(4) {
  transform: translateX(320px);   /* 右移 40px，可按需调整 */
}

.phys-shift .column:nth-of-type(3),
.phys-shift .column:nth-of-type(6) {
  transform: translateX(-320px);  /* 左移 40px，与上面保持一致即可 */
}

/* 窄屏时自动回正，避免内容超出屏幕 */
@media (max-width: 768px) {
  .phys-shift .column:nth-of-type(1),
  .phys-shift .column:nth-of-type(3),
  .phys-shift .column:nth-of-type(4),
  .phys-shift .column:nth-of-type(6) {
    transform: none;
  }
}
</style>

<style>
  /* 基础位移：第 1、3 个向右；第 2、4 个向左 */
  .phys-shift_ .column:nth-of-type(1) {
    transform: translateX(410px);
  }
  .phys-shift_ .column:nth-of-type(2) {
    transform: translateX(140px);   /* 右移 40px，可按需调整 */
  }
  
  .phys-shift_ .column:nth-of-type(3) {
    transform: translateX(-140px);
  }
  .phys-shift_ .column:nth-of-type(4) {
    transform: translateX(-410px);  /* 左移 40px，与上面保持一致即可 */
  }
  
  /* 窄屏时自动回正，避免内容超出屏幕 */
  @media (max-width: 768px) {
    .phys-shift_ .column:nth-of-type(1),
    .phys-shift_ .column:nth-of-type(2),
    .phys-shift_ .column:nth-of-type(3),
    .phys-shift_ .column:nth-of-type(4) {
      transform: none;
    }
  }
  </style>

<style>
  /* 基础位移：第 1、3 个向右；第 2、4 个向左 */
  .phys-shift__ .column:nth-of-type(1) {
    transform: translateX(360px);
  }
  .phys-shift__ .column:nth-of-type(2) {
    transform: translateX(120px);   /* 右移 40px，可按需调整 */
  }
  
  .phys-shift__ .column:nth-of-type(3) {
    transform: translateX(-120px);
  }
  .phys-shift__ .column:nth-of-type(4) {
    transform: translateX(-360px);  /* 左移 40px，与上面保持一致即可 */
  }
  .phys-shift__ .column:nth-of-type(5) {
    transform: translateX(360px);
  }
  .phys-shift__ .column:nth-of-type(6) {
    transform: translateX(120px);   /* 右移 40px，可按需调整 */
  }
  
  .phys-shift__ .column:nth-of-type(7) {
    transform: translateX(-120px);
  }
  .phys-shift__ .column:nth-of-type(8) {
    transform: translateX(-360px);  /* 左移 40px，与上面保持一致即可 */
  }
  
  /* 窄屏时自动回正，避免内容超出屏幕 */
  @media (max-width: 768px) {
    .phys-shift__ .column:nth-of-type(1),
    .phys-shift__ .column:nth-of-type(2),
    .phys-shift__ .column:nth-of-type(3),
    .phys-shift__ .column:nth-of-type(4),
    .phys-shift__ .column:nth-of-type(5),
    .phys-shift__ .column:nth-of-type(6),
    .phys-shift__ .column:nth-of-type(7),
    .phys-shift__ .column:nth-of-type(8) {
      transform: none;
    }
  }
  </style> -->


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="container is-max-maxwidth">
        <h2 class="title is-3">Amazing Generalization Capability For Downstream Tasks</h2>
        <div class="columns is-centered has-text-centered">
          <img width="800" height="600" src="static/paper_img/downstream.png" alt="downstream.png" />
        </div>
      </div>
    </div>
  </div>

  



  <h3 class="title has-text-centered">Class-to-Video Generation on UCF-101 Visualization</h3>
  <div class="columns is-multiline is-centered is-variable is-1 phys-shift">

    <!-- item 1 -->
    <div class="column is-4 has-text-centered">
      <video width="320" height="240" class="demo-video clickplay" controls>
        <source src="static/ucf_101/video1.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">BenchPress</p>
    </div>

    <!-- item 2 -->
    <div class="column is-4 has-text-centered">
      <video width="320" height="240" class="demo-video clickplay" controls>
        <source src="static/ucf_101/video2.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">ApplyLipstick</p>
    </div>

    <!-- item 3 -->
    <div class="column is-4 has-text-centered">
      <video width="320" height="240" class="demo-video clickplay" controls>
        <source src="static/ucf_101/video3.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">WallPushups</p>
    </div>

    <!-- item 4 -->
    <div class="column is-4 has-text-centered">
      <video width="320" height="240" class="demo-video clickplay" controls>
        <source src="static/ucf_101/video4.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">Skijet</p>
    </div>

    <!-- item 5 -->
    <div class="column is-4 has-text-centered">
      <video width="320" height="240" class="demo-video clickplay" controls>
        <source src="static/ucf_101/video5.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">BilliardsShot</p>
    </div>

    <!-- item 6 -->
    <div class="column is-4 has-text-centered">
      <video width="320" height="240" class="demo-video clickplay" controls>
        <source src="static/ucf_101/video6.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">CleanAndJerk</p>
    </div>

  </div>






  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="container is-max-maxwidth">
        <h3 class="title has-text-centered">Video Object Segmentation Visualization</h3>
        <video width="640" height="352" class="demo-video clickplay" controls>
          <source src="static/video_object_seg/video.mp4" type="video/mp4">
        </video>
        <p class="is-size-5 has-text-weight-bold">Fine-tuning 5K Step on 1000 data from GenIn-1M.</p>
      </div>
    </div>
  </div>







  <h3 class="title has-text-centered">Image Animation Visualization</h3>
  <div class="columns is-multiline is-centered is-variable is-1 phys-shift">

    <!-- item 1 -->
    <div class="column is-4 has-text-centered">
      <video width="224" height="320" class="demo-video clickplay" controls>
        <source src="static/image_animation/video1.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">lie down</p>
    </div>

    <!-- item 2 -->
    <div class="column is-4 has-text-centered">
      <video width="240" height="320" class="demo-video clickplay" controls>
        <source src="static/image_animation/video2.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">transform</p>
    </div>

    <!-- item 3 -->
    <div class="column is-4 has-text-centered">
      <video width="192" height="320" class="demo-video clickplay" controls>
        <source src="static/image_animation/video3.mp4" type="video/mp4">
      </video>
      <p class="is-size-5 has-text-weight-bold">fly</p>
    </div>

  </div>


</section>






<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website adapted from the following <a rel="license"
                                                href="https://github.com/nerfies/nerfies.github.io">source code</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>

<script>
var videos = document.getElementsByClassName("clickplay");
for (var i = 0; i < videos.length; i++) {
  videos[i].addEventListener("click", function() {
    this.play();
  });
  videos[i].addEventListener("ended", function() {
    this.pause();
    this.currentTime = 0;
  });
}
</script>

</html>
